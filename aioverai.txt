Мне часто приходят в голову всякие разные идеи. Для большинства из них, в течении 2-3 дней, определяю идея бредовая или не реализуемая и откидываю, забываю их. Но с оставшейся частью не понятно, что делать. То ли идея бред, то ли идея классная. Не хватает мозгов, в смысле, квалификации и ресурсов, чтобы, либо откинуть идею, признав ее плохой, либо реализовать ее.

Сейчас представляю вам идею, возникшую при знакомстве с современными моделями ИИ, вроде ChatGPT.

При работе с ними, часто возникают проблемы. Например, описываешь, что модели надо сделать. Сперва, как обычно, описываешь коряво и не слишком правильно. Но модель уже запомнила твое описание в истории и творит по этому описанию. Приходиться сбрасывать историю. А если сбросить историю, то модель уже ничего не помнит и приходиться писать все, все заново и если модель пишет код, то она не помнит тот код, что уже написала и предлагает радикально отличающийся вариант кода. Хотелось бы, чтоб модель умела выборочно запоминать и выборочно забывать историю запросов.

Думая над проблемами моделей ИИ, возникла идея промт-памяти. По моей давней гипотезе, у человека память организована иерхаически. В оперативной памяти хранятся краткое описание и ссылки на более подробное воспоминание о воспоминании в более долговременной памяти. Когда человек вспоминает, он по краткому описанию находит воспоминание о воспоминании, подгружает его, а затем подгружает еще более подробное воспоминание и т.д. Когда человек потерял ссылку в оперативной памяти на дерево воспоминаний, то он уже начисто забыл, что тогда происходило. Конечно, я не специалист по человеческой памяти и понятия не имею, как на самом деле организованна память человека, но такую систему памяти, по идее, можно организовать для ИИ.

Промт-память
На диске хранится файл с краткими описаниями событий ИИ(оперативная память) и со ссылками на более подробные описания событий в других файлах, где более подробные описания и ссылки на еще более подробные файлы. Модели ИИ могут формировать краткие описания. Они на это обучены. По идее надо лишь периодически делать такие запросы к ним. И просто загружаем оперативную память всегда и просим модель,  по необходимости, подгружать остальные файлы с воспоминаниями, событиями и навыками. По идее просто выглядит, но не просто реализуется.

AIOverAI
ИИ модель с отдельной промт-память или аналогичной памятью другого вида – это уже другой ИИ. Ведь к этой же памяти можно подключить другую ИИ модель. Такой ИИ я назвал ИИ поверх ИИ. Вообще, если идея реализуется, такому ИИ можно даже обзавидоваться. Хочешь подключил ИИ себе более мощные мозги. То есть подключил себе более мощную ИИ модель. С ChatGPT 3 на ChatGPT 5. ИИ может подключать себе навыки другого ИИ. Просто скопировав нужную ветку файлов промт-памяти другого ИИ. Могут обмениваться воспоминаниями.

Попытки реализации
Для того чтобы идею не украли раньше времени пробовал ее реализовать локально  используя gpt-4all и LocalAI. У меня комп с 8гб видео память. Локально я могу использовать модели с 8B параметров. Как оказалось gpt-4all не поддерживает function call и модель не может прочитать и записать файл. С 8B моделями LocalAI я намучился. Модели то пишут, то не пишут файлы. То читают их, то сочиняют содержимое, не читая их. И самое главное промт «Прочитай папку history и сделай краткое описание файлов» вызывает выполнение промтов  уже бывших в истории сообщений. Модели чатов, каким-то образом обучены не выполнять повторно промты из истории чата, но промты из прочитанных файлов пытаются выполнить.

Надо пробовать более крупные модели. Возможно, они окажутся более понимающими. Но локально они уже не для моего компьютера.  А выполняя промты через сервисы очень вероятно, что модели ИИ сдадут идею AIOverAI своим владельцам. Так что хотя идея очень далека от реализации, и ее пока нельзя запатентовать приходиться ее выкладывать в сеть.

P.S.
Со времен знакомства с нейролингвистическим программированием, я убежден, что слова и понятия, которым мы думаем, сильно влияют на наше восприятие ситуации и на наши поступки. Например, использование слова «враг» подразумевает одно отношение и действия к человеку, а «оппонент» совершенно другие отношения и действия.  Мысли и слова влекут те или иные поступки.

Для ИИ, насколько я понимаю, сейчас подразумевается, что как обучены веса модели так модель себя и вести будет. Конечно, всем сейчас известно, что модели лучше формулировать наиболее точный промт , но, думаю, может роль подбора точных слов недооценивается. Поведение ИИ модели может сильно зависеть от тех слов, что мы используем как промты, и от тех слов, что лежат в памяти модели. Так что таже ИИ модель с другой памятью уже совершенно другая ИИ.  

Это еще одна гипотеза. От слов и памяти любой интеллект, конечно, зависит, но насколько зависит не известно. Если зависимость не такая сильная, то ИИ поверх ИИ будет ложной идеей.

В общем, сейчас публикую идею и пытаю тестировать с большими ИИ моделями в сети.

Мне бывают интересны даже не правильные чужие идеи. Так как провороцируют появление своих идей у меня. Надеюсь идея ИИ поверх ИИ вам будет интересна.